{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cff5bdc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:51:42.346422Z",
     "iopub.status.busy": "2024-08-26T15:51:42.345680Z",
     "iopub.status.idle": "2024-08-26T15:51:48.314048Z",
     "shell.execute_reply": "2024-08-26T15:51:48.313059Z"
    },
    "id": "sG6GbZCo_zkI",
    "papermill": {
     "duration": 5.97887,
     "end_time": "2024-08-26T15:51:48.316487",
     "exception": false,
     "start_time": "2024-08-26T15:51:42.337617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1fb4794",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:51:48.330966Z",
     "iopub.status.busy": "2024-08-26T15:51:48.330541Z",
     "iopub.status.idle": "2024-08-26T15:51:48.335691Z",
     "shell.execute_reply": "2024-08-26T15:51:48.334821Z"
    },
    "id": "fSBBOfnh_zkJ",
    "papermill": {
     "duration": 0.014343,
     "end_time": "2024-08-26T15:51:48.337581",
     "exception": false,
     "start_time": "2024-08-26T15:51:48.323238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "args = {\n",
    "    \"train_path\" : \"/kaggle/input/2024-outta-basic-p-3/train/train\",\n",
    "    \"test_path\" : \"/kaggle/input/2024-outta-basic-p-3/test/test\",\n",
    "    \"submit_path\" : \"/kaggle/input/2024-outta-basic-p-3/sample_submission.csv\",\n",
    "    \"extract_features\" : \"spectral\",  # \"rhythm\"과 \"spectral\" 중에 선택하세요.\n",
    "    \"batch_size\" : 64,\n",
    "    \"num_labels\" : 2,\n",
    "    \"epochs\" : 20,\n",
    "    \"lr\" : 1e-4,\n",
    "    \"eps\" : 1e-8,\n",
    "    \"seed_val\" : 42     # 절대 수정하지 마세요.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37f02624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:51:48.351167Z",
     "iopub.status.busy": "2024-08-26T15:51:48.350898Z",
     "iopub.status.idle": "2024-08-26T15:51:48.445303Z",
     "shell.execute_reply": "2024-08-26T15:51:48.444321Z"
    },
    "id": "O6IbtKg3_zkJ",
    "papermill": {
     "duration": 0.103583,
     "end_time": "2024-08-26T15:51:48.447342",
     "exception": false,
     "start_time": "2024-08-26T15:51:48.343759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 랜덤시드 고정하기\n",
    "seed = args[\"seed_val\"]\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available() :\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# 디바이스 선택\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e3749a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:51:48.461759Z",
     "iopub.status.busy": "2024-08-26T15:51:48.461024Z",
     "iopub.status.idle": "2024-08-26T15:52:02.281162Z",
     "shell.execute_reply": "2024-08-26T15:52:02.279684Z"
    },
    "id": "VYJGBHsD_zkK",
    "papermill": {
     "duration": 13.829567,
     "end_time": "2024-08-26T15:52:02.283406",
     "exception": false,
     "start_time": "2024-08-26T15:51:48.453839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\r\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchsummary\n",
    "from torchsummary import summary as summary_## 모델 정보를 확인하기 위해 torchsummary 함수 import\n",
    "\n",
    "## 모델의 형태를 출력하기 위한 함수\n",
    "def summary_model(model, input_shape=(384,)):\n",
    "    model = model.to(device)\n",
    "    summary_(model, input_shape) ## (model, (input shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c78a97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.299087Z",
     "iopub.status.busy": "2024-08-26T15:52:02.298746Z",
     "iopub.status.idle": "2024-08-26T15:52:02.302977Z",
     "shell.execute_reply": "2024-08-26T15:52:02.302121Z"
    },
    "id": "ndKW6sQc_zkK",
    "papermill": {
     "duration": 0.014139,
     "end_time": "2024-08-26T15:52:02.304866",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.290727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # (선택) Ipython 라이브러리를 이용해 학습에 사용될 음성을 직접 들어볼 수 있습니다.\n",
    "# from IPython.display import Audio, display\n",
    "\n",
    "# filename = '/kaggle/input/2024-outta-basic-p-3/train/train/blues/blues.00000.wav'  # 파일 주소\n",
    "# y, sr = librosa.load(filename)\n",
    "# audio_wdt = Audio(data=y,rate=sr)\n",
    "# display(audio_wdt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efbc796",
   "metadata": {
    "id": "JKlz2TFH_zkK",
    "papermill": {
     "duration": 0.0066,
     "end_time": "2024-08-26T15:52:02.318361",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.311761",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **1. 데이터**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf84c0",
   "metadata": {
    "id": "hcjw9yGu_zkL",
    "papermill": {
     "duration": 0.006584,
     "end_time": "2024-08-26T15:52:02.331806",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.325222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **(1) Label Map**\n",
    "{'강아지' : 0, '고양이' : 1} 등과 같은 형식으로, 머신러닝, 딥러닝 모델들은 feature나 label의 값들이 숫자(정수/실수)인 것만 처리할 수 있기 때문에, 문자열일 경우 숫자형으로 변환하여 처리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3229668f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.346839Z",
     "iopub.status.busy": "2024-08-26T15:52:02.346250Z",
     "iopub.status.idle": "2024-08-26T15:52:02.350891Z",
     "shell.execute_reply": "2024-08-26T15:52:02.350036Z"
    },
    "id": "bsSl3jPk_zkL",
    "papermill": {
     "duration": 0.014056,
     "end_time": "2024-08-26T15:52:02.352693",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.338637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_map = {'blues': 0,\n",
    "             'classical': 1,\n",
    "             'country': 2,\n",
    "             'disco': 3,\n",
    "             'hiphop': 4,\n",
    "             'jazz': 5,\n",
    "             'metal': 6,\n",
    "             'pop': 7,\n",
    "             'reggae': 8,\n",
    "             'rock': 9}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ec6e4",
   "metadata": {
    "id": "9UtAKCyI_zkL",
    "papermill": {
     "duration": 0.006666,
     "end_time": "2024-08-26T15:52:02.366211",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.359545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **(2) Feature Extract**\n",
    "컴퓨터에 입력할 수 있도록 샘플링과 양자화를 거쳤다고 해도, 이를 바로 분류기에 넣는 것은 높은 성능을 보장할 수 없습니다.<br>\n",
    "이는 음성 정보 안에 여러 주파수가 섞여 있으며 방대한 정보를 담고 있기 때문입니다.<br>\n",
    "따라서 데이터 중 음성의 대표적인 성질을 나타낼 수 있는 handcrafted feature를 추출하여 사용하는 것이 필수적입니다.<br>\n",
    "데이터에서 어떠한 특징을 어떠한 방식으로 추출하는지에 따라 분류기 성능에 큰 영향을 끼칠 수 있기 때문에 feature 추출을 위해서는 신중한 설계가 선행되어야 합니다.<br>\n",
    "\n",
    "- 참고 1 : https://librosa.org/doc/latest/index.html\n",
    "- 참고 2 : https://wikidocs.net/192879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de86a986",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.381484Z",
     "iopub.status.busy": "2024-08-26T15:52:02.380979Z",
     "iopub.status.idle": "2024-08-26T15:52:02.387014Z",
     "shell.execute_reply": "2024-08-26T15:52:02.386162Z"
    },
    "id": "EojDQ7Gc_zkL",
    "papermill": {
     "duration": 0.015629,
     "end_time": "2024-08-26T15:52:02.388949",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.373320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_rhythm_features(file_path):\n",
    "    # 반환할 feature list 선언\n",
    "    feature = []\n",
    "    \n",
    "    # (1-1) librosa.load(): extract_rhythm_features() 함수의 인자로 넘겨 받은 file_path에 대하여 1초 당 22050개의 샘플을 추출한 time-series를 load합니다.\n",
    "    y, sr = librosa.load(file_path)\n",
    "    \n",
    "    # (1-2) librosa.onset.onset_strength(): 앞서 load한 time-series를 함수의 입력으로 주어 onset_envelope를 추출합니다.\n",
    "    onset_envelope = librosa.onset.onset_strength(y=y, sr=sr)\n",
    "    \n",
    "    # autocorrelation tempogram\n",
    "    # (1-3) librosa.feature.tempogram(): 앞서 추출한 onset_envelope와 sr을 함수의 입력으로 주어 autocorrelation tempogram feature를 추출합니다. 함수의 입력 변수를 잘 확인하세요.\n",
    "    tempogram = librosa.feature.tempogram(onset_envelope=onset_envelope, sr=sr)\n",
    "    \n",
    "    # (1-4) autocorrelation tempogram에 대해 시간 축으로 평균을 내고 절대값을 취해 복소수를 제거함으로써 tempogram_feature를 얻습니다.\n",
    "    tempogram_feature = np.abs(tempogram.mean(axis=1)) # (384, 1293) -> (384, ), 복소수를 없애기 위해 절대값 처리\n",
    "    \n",
    "    feature = tempogram_feature\n",
    "    \n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "376a3e7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.404764Z",
     "iopub.status.busy": "2024-08-26T15:52:02.403979Z",
     "iopub.status.idle": "2024-08-26T15:52:02.412672Z",
     "shell.execute_reply": "2024-08-26T15:52:02.411758Z"
    },
    "id": "2DTI_SZp_zkM",
    "papermill": {
     "duration": 0.018592,
     "end_time": "2024-08-26T15:52:02.414569",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.395977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_spectral_features(file_path):\n",
    "    # 반환할 feature list 선언\n",
    "    feature = []\n",
    "    \n",
    "    # (2-1) librosa.load(): extract_spectral_features() 함수의 인자로 넘겨 받은 file_path에 대하여 1초 당 22050개의 샘플을 추출한 time-series를 load합니다.  \n",
    "    y, sr = librosa.load(file_path)\n",
    "\n",
    "    # (2-2) librosa.stft(): 앞서 load한 time-series를 함수의 입력으로 주어 stft를 추출하고, 절대값을 취해 복소수를 제거한 spectrogram을 추출합니다.  \n",
    "    # * 이 때, 93ms의 물리적 간격으로 나뉘어 spectrogram이 생성될 수 있도록 하이퍼파라미터 n_fft를 조절합니다. 어떠한 값을 넣어야 하는지는 공식 문서를 참고하세요.\n",
    "    n_fft = int(0.093*sr)\n",
    "    spectrogram = np.abs(librosa.stft(y, n_fft=n_fft))\n",
    "    \n",
    "    # (2-3) 앞서 얻은 spectrogram에 제곱 연산을 취해 power_spectrogram을 얻습니다.  \n",
    "    power_spectrogram = spectrogram ** 2\n",
    "    \n",
    "    # (2-4) librosa.feature.melspectrogram(): 앞서 얻은 power_spectrogram을 함수의 입력으로 주어 melspectrogram을 추출합니다.  \n",
    "    melspectrogram = librosa.feature.melspectrogram(y=y,sr=sr,S=power_spectrogram, n_fft=n_fft)\n",
    "    \n",
    "    # (2-5) librosa.power_to_db(): 앞서 얻은 melspectrogram을 함수의 입력으로 주어 db scale로 변환된 melspectrogram_db를 추출합니다.  \n",
    "    melspectrogram_db = librosa.power_to_db(melspectrogram)\n",
    "    \n",
    "    # chromagram\n",
    "    # (2-6) librosa.feature.chroma_stft(): (2-3)에서 얻은 power_spectrogram을 함수의 입력으로 주어 chromagram을 추출합니다. 함수의 입력 변수를 잘 확인하세요.\n",
    "    chromagram = librosa.feature.chroma_stft(y=y,sr=sr,S=power_spectrogram)  # (12, 1293)\n",
    "    \n",
    "    # (2-7) chromagram에 대해 시간 축으로 평균을 내어 chromagram_feature를 얻습니다. \n",
    "    chromagram_feature = chromagram.mean(axis=1)  # (12, )\n",
    "    \n",
    "    # mfcc\n",
    "    # (2-8) librosa.feature.mfcc(): (2-5)에서 얻은 melspectrogram_db를 함수의 입력으로 주어 mfcc를 추출합니다. 함수의 입력 변수를 잘 확인하세요.\n",
    "    mfcc = librosa.feature.mfcc(y=y,sr=sr,S=melspectrogram_db)  # (20, 1293)\n",
    "    \n",
    "    # (2-9) mfcc에 대해 시간 축으로 평균을 내어 mfcc_feature를 얻습니다.  \n",
    "    mfcc_feature = mfcc.mean(axis=1)  # (20, )\n",
    "    \n",
    "    # (2-10) chromagram과 mfcc를 하나의 feature로 반환할 수 있도록 concatenate를 수행합니다.\n",
    "    feature = np.concatenate((chromagram_feature, mfcc_feature))\n",
    "\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47264e6",
   "metadata": {
    "id": "tejhaHVl_zkM",
    "papermill": {
     "duration": 0.006958,
     "end_time": "2024-08-26T15:52:02.428756",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.421798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## **(3) Custom Dataset**\n",
    "Custom Dataset 클래스는 크게 **__init__(), __len__(), 그리고 __getitem__()** 3개의 함수로 구현해야 합니다.\n",
    "\n",
    "1.  __init__()\n",
    "    - Dataset instance를 생성할 때 한번만 실행되는 함수로, 입력 이미지의 디렉토리와 라벨 정보 그리고 transform을 초기화 합니다.\n",
    "\n",
    "2. __len__()\n",
    "    - 데이터셋의 샘플 개수를 반환하는 함수 입니다.\n",
    "    \n",
    "3. __getitem__()\n",
    "    - 주어진 인덱스에 해당하는 데이터 샘플을 데이터셋에서 불러오고 반환하는 함수 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b533d72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.444372Z",
     "iopub.status.busy": "2024-08-26T15:52:02.444062Z",
     "iopub.status.idle": "2024-08-26T15:52:02.456243Z",
     "shell.execute_reply": "2024-08-26T15:52:02.455385Z"
    },
    "id": "JT_FxATr_zkM",
    "papermill": {
     "duration": 0.022073,
     "end_time": "2024-08-26T15:52:02.458096",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.436023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_path, split, extract_features, label_map):\n",
    "        self.split = split.upper()\n",
    "        self.root_path = root_path\n",
    "        self.extract_features = extract_features\n",
    "        self.label_map = label_map\n",
    "        \n",
    "        self.music = []\n",
    "        self.label = []\n",
    "        \n",
    "        # (3-1) test 데이터 디렉토리 경로 초기화\n",
    "        if self.split == 'TEST':\n",
    "            musics = sorted([f for f in os.listdir(self.root_path) if f.endswith('.wav')])\n",
    "            for music_ in musics:\n",
    "                music_path = os.path.join(self.root_path, music_)\n",
    "                self.music.append(music_path)\n",
    "                \n",
    "            \n",
    "        # (3-2) train 데이터 디렉토리 경로, 라벨 초기화\n",
    "        else:\n",
    "            genres = sorted(os.listdir(self.root_path))\n",
    "            for genre_ in genres:\n",
    "                genre_path = os.path.join(self.root_path, genre_)\n",
    "                if not os.path.isdir(genre_path):\n",
    "                    continue\n",
    "                musics = sorted([f for f in os.listdir(genre_path) if f.endswith('.wav')])\n",
    "                for music_ in musics:\n",
    "                    music_path = os.path.join(genre_path, music_)\n",
    "                    self.music.append(music_path)\n",
    "                    self.label.append(self.label_map[genre_])\n",
    "\n",
    "    # 전체 데이터 샘플 개수 반환\n",
    "    def __len__(self):\n",
    "        return len(self.music)\n",
    "    \n",
    "    # 주어진 인덱스에 해당하는 데이터 반환\n",
    "    def __getitem__(self, idx):        \n",
    "        # (3-3) 음악 데이터에 feature extract 적용\n",
    "        spectral_feature = extract_spectral_features(self.music[idx]).reshape(-1,1)\n",
    "        rhythm_feature = extract_rhythm_features(self.music[idx]).reshape(-1,1)\n",
    "        # spectral과 rhythm feature을 각각 minmax scale\n",
    "        spectral_scaler = MinMaxScaler()\n",
    "        rhythm_scaler = MinMaxScaler()\n",
    "        \n",
    "        normalized_spectral = spectral_scaler.fit_transform(spectral_feature)\n",
    "        normalized_rhythm = rhythm_scaler.fit_transform(rhythm_feature).reshape(-1,1)\n",
    "        # concatenate (384+32=416,)\n",
    "        music_feature = np.concatenate((spectral_feature,rhythm_feature)).squeeze()\n",
    "        \n",
    "        # (3-4) test에 사용할 데이터 반환\n",
    "        if self.split == 'TEST':\n",
    "            return music_feature\n",
    "        # (3-5) train에 사용할 데이터 반환\n",
    "        else:\n",
    "            label = self.label[idx]\n",
    "            return music_feature, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a01ce",
   "metadata": {
    "id": "iHKxJec__zkM",
    "papermill": {
     "duration": 0.007546,
     "end_time": "2024-08-26T15:52:02.472716",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.465170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### **(4) 데이터셋과 데이터로더**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f260ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.488817Z",
     "iopub.status.busy": "2024-08-26T15:52:02.488520Z",
     "iopub.status.idle": "2024-08-26T15:52:02.647212Z",
     "shell.execute_reply": "2024-08-26T15:52:02.646534Z"
    },
    "id": "sOKXC29P_zkM",
    "papermill": {
     "duration": 0.168987,
     "end_time": "2024-08-26T15:52:02.649095",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.480108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (4-1) 훈련 및 테스트 데이터셋 로드\n",
    "train_dataset = CustomDataset(root_path=args[\"train_path\"], split='train', extract_features=args[\"extract_features\"],label_map=label_map)\n",
    "test_dataset = CustomDataset(root_path=args[\"test_path\"], split='test', extract_features=args[\"extract_features\"],label_map=label_map)\n",
    "# (4-2) 데이터로더 정의\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=args[\"batch_size\"], shuffle=True,)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e1a249a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:02.665021Z",
     "iopub.status.busy": "2024-08-26T15:52:02.664746Z",
     "iopub.status.idle": "2024-08-26T15:52:16.003549Z",
     "shell.execute_reply": "2024-08-26T15:52:16.002199Z"
    },
    "id": "SnqtaZ2Q_zkM",
    "papermill": {
     "duration": 13.350117,
     "end_time": "2024-08-26T15:52:16.006870",
     "exception": false,
     "start_time": "2024-08-26T15:52:02.656753",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Music Data's shape : (416,)\n",
      "Test Music Data's shape : (416,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Train Music Data\\'s shape : {train_dataset.__getitem__(913)[0].shape}')   # train_dataset의 반환값 : music_feature, label\n",
    "print(f'Test Music Data\\'s shape : {test_dataset.__getitem__(299).shape}')        # test_dataset의 반환값 : music_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5368bed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:16.040854Z",
     "iopub.status.busy": "2024-08-26T15:52:16.039144Z",
     "iopub.status.idle": "2024-08-26T15:52:16.051036Z",
     "shell.execute_reply": "2024-08-26T15:52:16.049897Z"
    },
    "papermill": {
     "duration": 0.032374,
     "end_time": "2024-08-26T15:52:16.054789",
     "exception": false,
     "start_time": "2024-08-26T15:52:16.022415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "914\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.__len__())\n",
    "print(test_dataset.__len__())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e586084",
   "metadata": {
    "id": "1gJjnSjg_zkN",
    "papermill": {
     "duration": 0.012389,
     "end_time": "2024-08-26T15:52:16.083262",
     "exception": false,
     "start_time": "2024-08-26T15:52:16.070873",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **3. 모델**\n",
    "모델을 직접 설계하여 프로젝트를 수행하세요.\n",
    "\n",
    "직접 쌓기만 하신다면, 어떤 모델이든 사용 가능합니다.\n",
    "\n",
    "아래는 베이스라인 모델입니다.\n",
    "\n",
    "> ```\n",
    ">         Layer (type)               Output Shape         Param #\n",
    "> =================================================================\n",
    ">             Conv1d-1              [-1, 64, 384]             256\n",
    ">               ReLU-2              [-1, 64, 384]               0\n",
    ">             Conv1d-3              [-1, 64, 384]          12,352\n",
    ">               ReLU-4              [-1, 64, 384]               0\n",
    ">          MaxPool1d-5              [-1, 64, 192]               0\n",
    ">             Conv1d-6             [-1, 128, 192]          24,704\n",
    ">               ReLU-7             [-1, 128, 192]               0\n",
    ">             Conv1d-8             [-1, 128, 192]          49,280\n",
    ">               ReLU-9             [-1, 128, 192]               0\n",
    ">         MaxPool1d-10              [-1, 128, 96]               0\n",
    ">            Conv1d-11              [-1, 256, 96]          98,560\n",
    ">              ReLU-12              [-1, 256, 96]               0\n",
    ">            Conv1d-13              [-1, 256, 96]         196,864\n",
    ">              ReLU-14              [-1, 256, 96]               0\n",
    ">            Conv1d-15              [-1, 256, 96]         196,864\n",
    ">              ReLU-16              [-1, 256, 96]               0\n",
    ">         MaxPool1d-17              [-1, 256, 48]               0\n",
    ">            Conv1d-18              [-1, 512, 48]         393,728\n",
    ">              ReLU-19              [-1, 512, 48]               0\n",
    ">            Conv1d-20              [-1, 512, 48]         786,944\n",
    ">              ReLU-21              [-1, 512, 48]               0\n",
    ">            Conv1d-22              [-1, 512, 48]         786,944\n",
    ">              ReLU-23              [-1, 512, 48]               0\n",
    ">         MaxPool1d-24              [-1, 512, 24]               0\n",
    ">            Conv1d-25              [-1, 512, 24]         786,944\n",
    ">              ReLU-26              [-1, 512, 24]               0\n",
    ">            Conv1d-27              [-1, 512, 24]         786,944\n",
    ">              ReLU-28              [-1, 512, 24]               0\n",
    ">            Conv1d-29              [-1, 512, 24]         786,944\n",
    ">              ReLU-30              [-1, 512, 24]               0\n",
    ">         MaxPool1d-31              [-1, 512, 12]               0\n",
    "> AdaptiveAvgPool1d-32               [-1, 512, 1]               0\n",
    ">           Flatten-33                  [-1, 512]               0\n",
    ">            Linear-34                   [-1, 10]           5,130\n",
    "> =================================================================\n",
    "> Total params: 4,912,458\n",
    "> Trainable params: 4,912,458\n",
    "> Non-trainable params: 0\n",
    "> ----------------------------------------------------------------\n",
    "> Input size (MB): 0.00\n",
    "> Forward/backward pass size (MB): 4.74\n",
    "> Params size (MB): 18.74\n",
    "> Estimated Total Size (MB): 23.48\n",
    "> ----------------------------------------------------------------\n",
    "> ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b443d2ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:16.099412Z",
     "iopub.status.busy": "2024-08-26T15:52:16.099122Z",
     "iopub.status.idle": "2024-08-26T15:52:16.118262Z",
     "shell.execute_reply": "2024-08-26T15:52:16.117394Z"
    },
    "papermill": {
     "duration": 0.029418,
     "end_time": "2024-08-26T15:52:16.120305",
     "exception": false,
     "start_time": "2024-08-26T15:52:16.090887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# (5) 모델 설계\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        모델 초기화 함수입니다.\n",
    "        \"\"\"\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.conv_block1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1),  # Conv1d-1\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),                                                            # ReLU-2\n",
    "            nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=1), # Conv1d-3\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),                                                            # ReLU-4\n",
    "            nn.MaxPool1d(kernel_size=2)                                           # MaxPool1d-5\n",
    "        )\n",
    "        \n",
    "        self.conv_block2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1), # Conv1d-6\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),                                                             # ReLU-7\n",
    "            nn.Conv1d(in_channels=128, out_channels=128, kernel_size=3, padding=1),# Conv1d-8\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),                                                             # ReLU-9\n",
    "            nn.MaxPool1d(kernel_size=2)                                            # MaxPool1d-10\n",
    "        )\n",
    "        \n",
    "        self.conv_block3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1),# Conv1d-11\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),                                                             # ReLU-12\n",
    "            nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=1),# Conv1d-13\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),                                                             # ReLU-14\n",
    "            nn.Conv1d(in_channels=256, out_channels=256, kernel_size=3, padding=1),# Conv1d-15\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),                                                             # ReLU-16\n",
    "            nn.MaxPool1d(kernel_size=2)                                            # MaxPool1d-17\n",
    "        )\n",
    "        \n",
    "        self.conv_block4 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=256, out_channels=512, kernel_size=3, padding=1),# Conv1d-18\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),                                                             # ReLU-19\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1),# Conv1d-20\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),                                                             # ReLU-21\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1),# Conv1d-22\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),                                                             # ReLU-23\n",
    "            nn.MaxPool1d(kernel_size=2)                                            # MaxPool1d-24\n",
    "        )\n",
    "        \n",
    "        self.conv_block5 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1),# Conv1d-25\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),                                                             # ReLU-26\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1),# Conv1d-27\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),                                                             # ReLU-28\n",
    "            nn.Conv1d(in_channels=512, out_channels=512, kernel_size=3, padding=1),# Conv1d-29\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),                                                             # ReLU-30\n",
    "            nn.MaxPool1d(kernel_size=2),                                        # MaxPool1d-31\n",
    "            nn.AdaptiveAvgPool1d(1),  # AdaptiveAvgPool1d-32\n",
    "            nn.Flatten()           # Flatten-33\n",
    "        )\n",
    "        # Classifier block\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 10), # Linear-34, class=10\n",
    "            nn.BatchNorm1d(10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        모델의 순전파 함수입니다.\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): 입력 데이터\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: 출력 예측값\n",
    "        \"\"\"\n",
    "        x = self.conv_block1(x)\n",
    "        x = self.conv_block2(x)\n",
    "        x = self.conv_block3(x)\n",
    "        x = self.conv_block4(x)\n",
    "        x = self.conv_block5(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9405dd43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:16.136720Z",
     "iopub.status.busy": "2024-08-26T15:52:16.136242Z",
     "iopub.status.idle": "2024-08-26T15:52:17.005589Z",
     "shell.execute_reply": "2024-08-26T15:52:17.004551Z"
    },
    "id": "cVMabhPS_zkN",
    "papermill": {
     "duration": 0.880171,
     "end_time": "2024-08-26T15:52:17.008006",
     "exception": false,
     "start_time": "2024-08-26T15:52:16.127835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 64, 416]             256\n",
      "       BatchNorm1d-2              [-1, 64, 416]             128\n",
      "              ReLU-3              [-1, 64, 416]               0\n",
      "            Conv1d-4              [-1, 64, 416]          12,352\n",
      "       BatchNorm1d-5              [-1, 64, 416]             128\n",
      "              ReLU-6              [-1, 64, 416]               0\n",
      "         MaxPool1d-7              [-1, 64, 208]               0\n",
      "            Conv1d-8             [-1, 128, 208]          24,704\n",
      "       BatchNorm1d-9             [-1, 128, 208]             256\n",
      "             ReLU-10             [-1, 128, 208]               0\n",
      "           Conv1d-11             [-1, 128, 208]          49,280\n",
      "      BatchNorm1d-12             [-1, 128, 208]             256\n",
      "             ReLU-13             [-1, 128, 208]               0\n",
      "        MaxPool1d-14             [-1, 128, 104]               0\n",
      "           Conv1d-15             [-1, 256, 104]          98,560\n",
      "      BatchNorm1d-16             [-1, 256, 104]             512\n",
      "             ReLU-17             [-1, 256, 104]               0\n",
      "           Conv1d-18             [-1, 256, 104]         196,864\n",
      "      BatchNorm1d-19             [-1, 256, 104]             512\n",
      "             ReLU-20             [-1, 256, 104]               0\n",
      "           Conv1d-21             [-1, 256, 104]         196,864\n",
      "      BatchNorm1d-22             [-1, 256, 104]             512\n",
      "             ReLU-23             [-1, 256, 104]               0\n",
      "        MaxPool1d-24              [-1, 256, 52]               0\n",
      "           Conv1d-25              [-1, 512, 52]         393,728\n",
      "      BatchNorm1d-26              [-1, 512, 52]           1,024\n",
      "             ReLU-27              [-1, 512, 52]               0\n",
      "           Conv1d-28              [-1, 512, 52]         786,944\n",
      "      BatchNorm1d-29              [-1, 512, 52]           1,024\n",
      "             ReLU-30              [-1, 512, 52]               0\n",
      "           Conv1d-31              [-1, 512, 52]         786,944\n",
      "      BatchNorm1d-32              [-1, 512, 52]           1,024\n",
      "             ReLU-33              [-1, 512, 52]               0\n",
      "        MaxPool1d-34              [-1, 512, 26]               0\n",
      "           Conv1d-35              [-1, 512, 26]         786,944\n",
      "      BatchNorm1d-36              [-1, 512, 26]           1,024\n",
      "             ReLU-37              [-1, 512, 26]               0\n",
      "           Conv1d-38              [-1, 512, 26]         786,944\n",
      "      BatchNorm1d-39              [-1, 512, 26]           1,024\n",
      "             ReLU-40              [-1, 512, 26]               0\n",
      "           Conv1d-41              [-1, 512, 26]         786,944\n",
      "      BatchNorm1d-42              [-1, 512, 26]           1,024\n",
      "             ReLU-43              [-1, 512, 26]               0\n",
      "        MaxPool1d-44              [-1, 512, 13]               0\n",
      "AdaptiveAvgPool1d-45               [-1, 512, 1]               0\n",
      "          Flatten-46                  [-1, 512]               0\n",
      "           Linear-47                   [-1, 10]           5,130\n",
      "      BatchNorm1d-48                   [-1, 10]              20\n",
      "================================================================\n",
      "Total params: 4,920,926\n",
      "Trainable params: 4,920,926\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 7.47\n",
      "Params size (MB): 18.77\n",
      "Estimated Total Size (MB): 26.25\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 모델을 장치로 이동\n",
    "model = Model().to(device)\n",
    "\n",
    "# 가중치 초기화 함수 정의\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Conv1d):\n",
    "        nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')  # He 초기화\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)  # 바이어스를 0으로 초기화\n",
    "\n",
    "# 모델에 초기화 함수 적용\n",
    "model.apply(initialize_weights)\n",
    "\n",
    "# 모델 요약 정보 출력\n",
    "summary_model(model, input_shape=(1,416))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0391cd21",
   "metadata": {
    "id": "cr-PGwFW_zkN",
    "papermill": {
     "duration": 0.007732,
     "end_time": "2024-08-26T15:52:17.023692",
     "exception": false,
     "start_time": "2024-08-26T15:52:17.015960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **4. 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cccdbde6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T15:52:17.041171Z",
     "iopub.status.busy": "2024-08-26T15:52:17.040232Z",
     "iopub.status.idle": "2024-08-26T17:20:35.100527Z",
     "shell.execute_reply": "2024-08-26T17:20:35.099572Z"
    },
    "id": "N8ZjHdu8_zkN",
    "papermill": {
     "duration": 5298.072297,
     "end_time": "2024-08-26T17:20:35.103792",
     "exception": false,
     "start_time": "2024-08-26T15:52:17.031495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:32<00:00, 18.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_1.pth\n",
      "Train Loss : 1.7486816724141439, Train Accuracy : 0.40043763676148797\n",
      "\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:27<00:00, 17.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_2.pth\n",
      "Train Loss : 1.341270112991333, Train Accuracy : 0.587527352297593\n",
      "\n",
      "Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:23<00:00, 17.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_3.pth\n",
      "Train Loss : 1.142771323521932, Train Accuracy : 0.688183807439825\n",
      "\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:23<00:00, 17.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_4.pth\n",
      "Train Loss : 1.0372423609097798, Train Accuracy : 0.7352297592997812\n",
      "\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:26<00:00, 17.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_5.pth\n",
      "Train Loss : 0.9284180164337158, Train Accuracy : 0.7986870897155361\n",
      "\n",
      "Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:26<00:00, 17.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_6.pth\n",
      "Train Loss : 0.8645109057426452, Train Accuracy : 0.8457330415754923\n",
      "\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:23<00:00, 17.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_7.pth\n",
      "Train Loss : 0.8093921820322673, Train Accuracy : 0.8687089715536105\n",
      "\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:22<00:00, 17.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_8.pth\n",
      "Train Loss : 0.7562162796656291, Train Accuracy : 0.9059080962800875\n",
      "\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:22<00:00, 17.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_9.pth\n",
      "Train Loss : 0.7550699631373088, Train Accuracy : 0.9080962800875274\n",
      "\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:29<00:00, 17.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_10.pth\n",
      "Train Loss : 0.7344720244407654, Train Accuracy : 0.9048140043763676\n",
      "\n",
      "Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:25<00:00, 17.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_11.pth\n",
      "Train Loss : 0.6789522886276245, Train Accuracy : 0.936542669584245\n",
      "\n",
      "Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:26<00:00, 17.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_12.pth\n",
      "Train Loss : 0.6391815026601155, Train Accuracy : 0.9540481400437637\n",
      "\n",
      "Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:24<00:00, 17.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_13.pth\n",
      "Train Loss : 0.6032955725987752, Train Accuracy : 0.9573304157549234\n",
      "\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:24<00:00, 17.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_14.pth\n",
      "Train Loss : 0.5550795237223307, Train Accuracy : 0.9770240700218819\n",
      "\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:25<00:00, 17.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_15.pth\n",
      "Train Loss : 0.5539579133192698, Train Accuracy : 0.9726477024070022\n",
      "\n",
      "Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:25<00:00, 17.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_16.pth\n",
      "Train Loss : 0.5101248542467753, Train Accuracy : 0.9857768052516411\n",
      "\n",
      "Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:23<00:00, 17.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_17.pth\n",
      "Train Loss : 0.5025076488653819, Train Accuracy : 0.9846827133479212\n",
      "\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:21<00:00, 17.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_18.pth\n",
      "Train Loss : 0.45580325921376547, Train Accuracy : 0.9923413566739606\n",
      "\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:22<00:00, 17.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_19.pth\n",
      "Train Loss : 0.43005738655726117, Train Accuracy : 0.9967177242888403\n",
      "\n",
      "Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [04:19<00:00, 17.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CheckPoint : model_state_dict_epoch_20.pth\n",
      "Train Loss : 0.41964129408200584, Train Accuracy : 0.9956236323851203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def train(train_dataloader, model, device, args):\n",
    "    \"\"\"\n",
    "    모델을 훈련시키는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        train_dataloader (DataLoader): 훈련 데이터가 포함된 데이터로더\n",
    "        model (nn.Module): 훈련할 신경망 모델\n",
    "        device (torch.device): 모델과 데이터를 올릴 장치 (CPU 또는 GPU)\n",
    "        args (dict): 훈련 설정을 포함한 딕셔너리 (예: 에포크 수)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # (6-1) 옵티마이저와 손실 함수 정의\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=args[\"lr\"],eps=args[\"eps\"])\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # 모델의 모든 파라미터의 기울기를 0으로 초기화\n",
    "    model.zero_grad()\n",
    "    \n",
    "    # 지정된 에포크 수만큼 훈련 반복\n",
    "    for epoch in range(args[\"epochs\"]):\n",
    "        print(f'Epoch {epoch + 1}/{args[\"epochs\"]}')\n",
    "        \n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        \n",
    "        # 훈련 데이터로더에서 데이터를 반복적으로 가져옴\n",
    "        for data, label in tqdm(train_dataloader):\n",
    "            # 데이터를 부동 소수점 형식으로 변환하고 장치에 올림\n",
    "            data = data.unsqueeze(1).float().to(device)\n",
    "            label = label.long().to(device)\n",
    "            # (6-2) 모델을 사용하여 예측 수행\\\n",
    "            pred = model(data)\n",
    "            # (6-3) 예측값과 실제 라벨을 사용하여 손실 계산\n",
    "            loss = loss_fn(pred,label)\n",
    "            # (6-4) 옵티마이저의 기울기를 초기화\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # (6-5) 역전파를 통해 기울기 계산\n",
    "            loss.backward()\n",
    "            \n",
    "            # (6-6) 옵티마이저를 사용하여 모델의 파라미터 업데이트\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 총 손실 계산\n",
    "            train_loss += loss.item()\n",
    "            # 예측값에서 가장 높은 값의 인덱스를 선택\n",
    "            pred = pred.argmax(dim=1)\n",
    "            # 정확도 계산\n",
    "            train_acc += (pred == label).sum().item()\n",
    "            \n",
    "        # 평균 손실과 정확도 계산\n",
    "        train_loss /= len(train_dataloader)\n",
    "        train_acc /= len(train_dataloader.dataset)\n",
    "            \n",
    "        # 모델과 옵티마이저 상태를 저장\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model': model,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            }, f'./results/model_state_dict_epoch_{epoch+1}.pth')\n",
    "            \n",
    "        # 현재 에포크의 손실과 정확도 출력\n",
    "        print(f'CheckPoint : model_state_dict_epoch_{epoch+1}.pth')\n",
    "        print(f'Train Loss : {train_loss}, Train Accuracy : {train_acc}\\n')\n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 훈련 함수 호출\n",
    "    train(train_dataloader, model, device, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7682e65",
   "metadata": {
    "id": "mCvVs0ET_zkN",
    "papermill": {
     "duration": 0.036045,
     "end_time": "2024-08-26T17:20:35.176438",
     "exception": false,
     "start_time": "2024-08-26T17:20:35.140393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **5. 평가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a08caa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T17:20:35.250129Z",
     "iopub.status.busy": "2024-08-26T17:20:35.249813Z",
     "iopub.status.idle": "2024-08-26T17:22:05.491781Z",
     "shell.execute_reply": "2024-08-26T17:22:05.489452Z"
    },
    "id": "yH3NGsx6_zkN",
    "papermill": {
     "duration": 90.281414,
     "end_time": "2024-08-26T17:22:05.494033",
     "exception": false,
     "start_time": "2024-08-26T17:20:35.212619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [01:30<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "def test(test_dataloader, model, device):\n",
    "    \"\"\"\n",
    "    모델의 예측을 수행하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        test_dataloader (DataLoader): 테스트 데이터가 포함된 데이터로더\n",
    "        model (nn.Module): 예측에 사용할 신경망 모델\n",
    "        device (torch.device): 모델과 데이터를 올릴 장치 (CPU 또는 GPU)\n",
    "\n",
    "    Returns:\n",
    "        preds (list): 예측된 클래스의 정수 인덱스 리스트\n",
    "    \"\"\"\n",
    "    # 모델을 평가 모드로 전환\n",
    "    model.eval()\n",
    "    # 예측 결과를 저장할 리스트 초기화\n",
    "    preds = []\n",
    "    \n",
    "    # 데이터로더에서 데이터를 반복적으로 가져옴\n",
    "    for data in tqdm(test_dataloader):\n",
    "        # 데이터를 부동 소수점 형식으로 변환하고 장치에 올림\n",
    "        data = data.unsqueeze(1).float().to(device)\n",
    "        # 기울기 계산을 비활성화하여 예측 수행\n",
    "        with torch.no_grad():\n",
    "            # (7-1) 모델을 사용하여 예측 수행\n",
    "            pred = model(data)\n",
    "            # (7-2) argmax를 이용하여 예측 결과에서 가장 높은 값의 인덱스를 선택\n",
    "            pred = pred.argmax(dim=1)\n",
    "            \n",
    "            # (7-3) 예측 결과를 리스트에 추가\n",
    "            preds.append(pred)\n",
    "            \n",
    "    return preds\n",
    "            \n",
    "\n",
    "def int_to_label(label_map, predictions_int):\n",
    "    \"\"\"\n",
    "    정수 형태의 예측값 리스트를 클래스 라벨로 변환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        label_map (dict): 클래스 라벨과 정수 인덱스 매핑이 저장된 딕셔너리\n",
    "        predictions_int (list): 정수 형태의 예측값 리스트\n",
    "\n",
    "    Returns:\n",
    "        predicted_labels (list): 문자열 형태의 예측 클래스 라벨 리스트\n",
    "    \"\"\"\n",
    "    # 정수 예측값을 클래스 라벨로 변환하여 리스트에 저장\n",
    "    predicted_labels = [list(label_map.keys())[list(label_map.values()).index(pred)] for pred in predictions_int]\n",
    "    \n",
    "    return predicted_labels\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 예측값을 얻기 위해 test 함수 호출\n",
    "    preds = test(test_dataloader, model, device)\n",
    "    \n",
    "    # 정수 예측값을 클래스 라벨로 변환\n",
    "    preds = int_to_label(label_map, preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54920322",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T17:22:05.617897Z",
     "iopub.status.busy": "2024-08-26T17:22:05.617010Z",
     "iopub.status.idle": "2024-08-26T17:22:05.640109Z",
     "shell.execute_reply": "2024-08-26T17:22:05.639228Z"
    },
    "id": "OEvhg6Fm_zkO",
    "papermill": {
     "duration": 0.086169,
     "end_time": "2024-08-26T17:22:05.642087",
     "exception": false,
     "start_time": "2024-08-26T17:22:05.555918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submit = pd.read_csv(args[\"submit_path\"])\n",
    "submit['genre'] = preds\n",
    "submit.to_csv('submission_p3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d301684",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-26T17:22:05.764072Z",
     "iopub.status.busy": "2024-08-26T17:22:05.763793Z",
     "iopub.status.idle": "2024-08-26T17:22:05.779418Z",
     "shell.execute_reply": "2024-08-26T17:22:05.778558Z"
    },
    "id": "hew6y_Zt_zkO",
    "papermill": {
     "duration": 0.080006,
     "end_time": "2024-08-26T17:22:05.781351",
     "exception": false,
     "start_time": "2024-08-26T17:22:05.701345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>music</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.wav</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.wav</td>\n",
       "      <td>disco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.wav</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.wav</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.wav</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0296.wav</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0297.wav</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0298.wav</td>\n",
       "      <td>disco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>0299.wav</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0300.wav</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        music      genre\n",
       "0    0001.wav       jazz\n",
       "1    0002.wav      disco\n",
       "2    0003.wav       jazz\n",
       "3    0004.wav       rock\n",
       "4    0005.wav     hiphop\n",
       "..        ...        ...\n",
       "295  0296.wav  classical\n",
       "296  0297.wav      metal\n",
       "297  0298.wav      disco\n",
       "298  0299.wav       rock\n",
       "299  0300.wav       jazz\n",
       "\n",
       "[300 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9018673,
     "sourceId": 82520,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5427.876568,
   "end_time": "2024-08-26T17:22:07.663012",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-26T15:51:39.786444",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
